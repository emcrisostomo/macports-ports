# -*- coding: utf-8; mode: tcl; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*- vim:fenc=utf-8:ft=tcl:et:sw=4:ts=4:sts=4

PortSystem              1.0
PortGroup               github 1.0
PortGroup               cmake 1.1
PortGroup               legacysupport 1.1

github.setup            ggerganov llama.cpp 4240 b
github.tarball_from     archive
set git-commit          642330a
# This line is for displaying commit in CLI only
revision                0
categories              sysutils
maintainers             {i0ntempest @i0ntempest} openmaintainer
license                 MIT

description             LLM inference in C/C++
long_description        The main goal of llama.cpp is to enable LLM inference with minimal\
                        setup and state-of-the-art performance on a wide variety of hardware\
                         - locally and in the cloud.

checksums               rmd160  1fc545de2c73469a7da0bbdd62e31489b546f982 \
                        sha256  6616c648bc47efe72beec358e7cf50efb8096842b9c93a99ba3d5d6fb4da430b \
                        size    19580582

# clock_gettime
legacysupport.newest_darwin_requires_legacy \
                        15

depends_lib-append      port:curl

# cmake relies on git for version info. We need to set them manually.
post-patch {
    reinplace "s|@BUILD_NUMBER@|${version}|" ${worksrcpath}/common/build-info.cpp.in
    reinplace "s|@BUILD_COMMIT@|${git-commit}|" ${worksrcpath}/common/build-info.cpp.in
}

compiler.cxx_standard   2017

configure.args-append   -DGGML_LTO=ON \
                        -DGGML_CCACHE=OFF \
                        -DLLAMA_CURL=ON

if {${os.platform} eq "darwin" && ${os.subplatform} eq "macosx" && ${os.major} > 14} {
    configure.args-append \
                        -DGGML_METAL=ON \
                        -DGGML_METAL_EMBED_LIBRARY=ON \
                        -DGGML_METAL_MACOSX_VERSION_MIN=${macos_version_major}
} else {
    configure.args-append \
                        -DGGML_METAL=OFF \
                        -DGGML_METAL_EMBED_LIBRARY=OFF
}

variant blas description {Uses BLAS, improves performance} {
    configure.args-append \
                        -DGGML_BLAS=ON
    if {${os.platform} eq "darwin" && ${os.subplatform} eq "macosx"} {
        configure.args-append \
                        -DGGML_ACCELLERATE=ON \
                        -DGGML_BLAS_VENDOR=Apple
    } else {
        configure.args-append \
                        -DGGML_ACCELLERATE=OFF \
                        -DGGML_BLAS_VENDOR=OpenBLAS

        depends_lib-append  path:lib/libopenblas.dylib:OpenBLAS
    }
}

variant native description "Force local build and optimize for CPU" {
    configure.args-append \
                        -DGGML_NATIVE=ON
}

default_variants        +blas
